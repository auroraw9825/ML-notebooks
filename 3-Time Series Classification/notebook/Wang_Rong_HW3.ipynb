{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9cc8457",
   "metadata": {},
   "source": [
    "Rong Wang, rongwww, 1619779944"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e16498",
   "metadata": {},
   "source": [
    "<b>1. Time Series Classification Part 1: Feature Creation/Extraction</b>\n",
    "\n",
    "An interesting task in machine learning is classification of time series. In this problem, we will classify the activities of humans based on time series obtained by a Wireless Sensor Network.\n",
    "\n",
    "(a) Download the AReM data from: https://archive.ics.uci.edu/ml/datasets/ Activity+Recognition+system+based+on+Multisensor+data+fusion+\\%28AReM\\ %29 . The dataset contains 7 folders that represent seven types of activities. In each folder, there are multiple files each of which represents an instant of a human performing an activity.1 Each file containis 6 time series collected from activities\n",
    "of the same person, which are called avg rss12, var rss12, avg rss13, var rss13, vg rss23, and ar rss23. There are 88 instances in the dataset, each of which con- tains 6 time series and each time series has 480 consecutive values.\n",
    "\n",
    "(b) Keep datasets 1 and 2 in folders bending1 and bending 2, as well as datasets 1, 2, and 3 in other folders as test data and other datasets as train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "92bfa7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from astropy.stats import bootstrap\n",
    "import statistics\n",
    "from numpy import mean\n",
    "from numpy import median\n",
    "from numpy import percentile\n",
    "import scipy as sp\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "813601cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size: 69 lines (480, 7)\n",
      "testset size: 19 lines (480, 7)\n"
     ]
    }
   ],
   "source": [
    "dir_path = '../data/AReM/'\n",
    "folders = ['bending1', 'bending2', 'cycling', 'lying', 'sitting', 'standing', 'walking']\n",
    "col_name = ['time', 'avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\n",
    "# 69 train datasets\n",
    "traindata_path_num = [[3, 4, 5, 6, 7], \n",
    "                      [3, 4, 5, 6], \n",
    "                      [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "                      [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "                      [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "                      [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "                      [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]\n",
    "# 19 test datasets\n",
    "testdata_path_num = [[1, 2], [1, 2], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]]\n",
    "\n",
    "trainset, testset = [], []\n",
    "\n",
    "# train data\n",
    "for folder_num in range(len(folders)):\n",
    "    folder_name = folders[folder_num]\n",
    "    dataset_num = traindata_path_num[folder_num]\n",
    "    for i in dataset_num:\n",
    "        file_path = dir_path + folder_name + \"/\" + \"dataset\" + str(i) + \".csv\"\n",
    "        if file_path == '../data/AReM/bending2/dataset4.csv':\n",
    "            dataframe = pd.read_csv(file_path, skiprows=5, header=None, delim_whitespace=True, names=col_name)\n",
    "        else:\n",
    "            dataframe = pd.read_csv(file_path, skiprows=5, encoding='utf-8', names=col_name)\n",
    "        trainset.append(dataframe)\n",
    "#         print(file_path + \" size: \" + str(dataframe.shape))\n",
    "    \n",
    "# test data\n",
    "for folder_num in range(len(folders)):\n",
    "    folder_name = folders[folder_num]\n",
    "    dataset_num = testdata_path_num[folder_num]\n",
    "    for i in dataset_num:\n",
    "        file_path = dir_path + folder_name + \"/\" + \"dataset\" + str(i) + \".csv\"\n",
    "        dataframe = pd.read_csv(file_path, skiprows=5, encoding='utf-8', names=col_name)\n",
    "        testset.append(dataframe)\n",
    "#         print(file_path + \" size: \" + str(dataframe.shape))          \n",
    "            \n",
    "print(\"trainset size: \" + str(len(trainset)) + \" lines \" + str(trainset[0].shape))\n",
    "print(\"testset size: \" + str(len(testset)) + \" lines \" + str(testset[0].shape))          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3ca98",
   "metadata": {},
   "source": [
    "(c) Feature Extraction\n",
    "Classification of time series usually needs extracting features from them. In this problem, we focus on time-domain features.\n",
    "\n",
    "i. Research what types of time-domain features are usually used in time series classification and list them (examples are minimum, maximum, mean, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce7b1ab",
   "metadata": {},
   "source": [
    "minimum, maximum, mean, median, standard deviation, first quartile, third quartile, range, skewness, kurtosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a59dd",
   "metadata": {},
   "source": [
    "ii. Extract the time-domain features minimum, maximum, mean, median, stan- dard deviation, first quartile, and third quartile for all of the 6 time series in each instance. You are free to normalize/standardize features or use them directly.\n",
    "\n",
    "For example, 1st quart6, means the first quartile of the sixth time series in each of the 88 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f7a96a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min1</th>\n",
       "      <th>max1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>median1</th>\n",
       "      <th>std1</th>\n",
       "      <th>1st_quartile1</th>\n",
       "      <th>3rd_quartile1</th>\n",
       "      <th>min2</th>\n",
       "      <th>max2</th>\n",
       "      <th>mean2</th>\n",
       "      <th>...</th>\n",
       "      <th>std5</th>\n",
       "      <th>1st_quartile5</th>\n",
       "      <th>3rd_quartile5</th>\n",
       "      <th>min6</th>\n",
       "      <th>max6</th>\n",
       "      <th>mean6</th>\n",
       "      <th>median6</th>\n",
       "      <th>std6</th>\n",
       "      <th>1st_quartile6</th>\n",
       "      <th>3rd_quartile6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>43.954500</td>\n",
       "      <td>44.330</td>\n",
       "      <td>1.558835</td>\n",
       "      <td>43.00</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.426250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.999604</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>36.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.513506</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179813</td>\n",
       "      <td>43.500</td>\n",
       "      <td>3.670666</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.696042</td>\n",
       "      <td>...</td>\n",
       "      <td>3.849448</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.524317</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.750</td>\n",
       "      <td>2.243490</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.535979</td>\n",
       "      <td>...</td>\n",
       "      <td>2.411026</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.389164</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>43.454958</td>\n",
       "      <td>43.250</td>\n",
       "      <td>1.386098</td>\n",
       "      <td>42.50</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.378083</td>\n",
       "      <td>...</td>\n",
       "      <td>2.488862</td>\n",
       "      <td>22.2500</td>\n",
       "      <td>24.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.679646</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.622534</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.25</td>\n",
       "      <td>48.00</td>\n",
       "      <td>43.969125</td>\n",
       "      <td>44.500</td>\n",
       "      <td>1.618364</td>\n",
       "      <td>43.31</td>\n",
       "      <td>44.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.413125</td>\n",
       "      <td>...</td>\n",
       "      <td>3.318301</td>\n",
       "      <td>20.5000</td>\n",
       "      <td>23.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.555313</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.487826</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>35.50</td>\n",
       "      <td>46.25</td>\n",
       "      <td>43.174938</td>\n",
       "      <td>43.670</td>\n",
       "      <td>1.989052</td>\n",
       "      <td>42.50</td>\n",
       "      <td>44.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.506583</td>\n",
       "      <td>...</td>\n",
       "      <td>2.983976</td>\n",
       "      <td>12.7500</td>\n",
       "      <td>16.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>0.911979</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.666161</td>\n",
       "      <td>0.470</td>\n",
       "      <td>1.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>32.75</td>\n",
       "      <td>47.00</td>\n",
       "      <td>42.760563</td>\n",
       "      <td>44.500</td>\n",
       "      <td>3.398919</td>\n",
       "      <td>41.33</td>\n",
       "      <td>45.3725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.486167</td>\n",
       "      <td>...</td>\n",
       "      <td>4.296574</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>18.565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.842271</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.722165</td>\n",
       "      <td>0.430</td>\n",
       "      <td>1.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>19.33</td>\n",
       "      <td>43.50</td>\n",
       "      <td>34.227771</td>\n",
       "      <td>35.500</td>\n",
       "      <td>4.889576</td>\n",
       "      <td>30.50</td>\n",
       "      <td>37.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.50</td>\n",
       "      <td>3.995729</td>\n",
       "      <td>...</td>\n",
       "      <td>3.092094</td>\n",
       "      <td>14.7500</td>\n",
       "      <td>18.670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>3.394125</td>\n",
       "      <td>3.100</td>\n",
       "      <td>1.792090</td>\n",
       "      <td>2.105</td>\n",
       "      <td>4.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>12.50</td>\n",
       "      <td>45.00</td>\n",
       "      <td>33.509729</td>\n",
       "      <td>34.125</td>\n",
       "      <td>4.850923</td>\n",
       "      <td>30.50</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.05</td>\n",
       "      <td>4.450771</td>\n",
       "      <td>...</td>\n",
       "      <td>3.133564</td>\n",
       "      <td>14.6275</td>\n",
       "      <td>18.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.96</td>\n",
       "      <td>3.378479</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1.787360</td>\n",
       "      <td>2.060</td>\n",
       "      <td>4.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>15.00</td>\n",
       "      <td>46.75</td>\n",
       "      <td>34.660583</td>\n",
       "      <td>35.000</td>\n",
       "      <td>5.315110</td>\n",
       "      <td>31.00</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.44</td>\n",
       "      <td>4.200896</td>\n",
       "      <td>...</td>\n",
       "      <td>3.155015</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>18.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.99</td>\n",
       "      <td>3.244396</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.630983</td>\n",
       "      <td>2.120</td>\n",
       "      <td>4.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     min1   max1      mean1  median1      std1  1st_quartile1  3rd_quartile1  \\\n",
       "1   35.00  47.40  43.954500   44.330  1.558835          43.00        45.0000   \n",
       "2   33.00  47.75  42.179813   43.500  3.670666          39.15        45.0000   \n",
       "3   33.00  45.75  41.678063   41.750  2.243490          41.33        42.7500   \n",
       "4   37.00  48.00  43.454958   43.250  1.386098          42.50        45.0000   \n",
       "5   36.25  48.00  43.969125   44.500  1.618364          43.31        44.6700   \n",
       "..    ...    ...        ...      ...       ...            ...            ...   \n",
       "84  35.50  46.25  43.174938   43.670  1.989052          42.50        44.5000   \n",
       "85  32.75  47.00  42.760563   44.500  3.398919          41.33        45.3725   \n",
       "86  19.33  43.50  34.227771   35.500  4.889576          30.50        37.7500   \n",
       "87  12.50  45.00  33.509729   34.125  4.850923          30.50        36.7500   \n",
       "88  15.00  46.75  34.660583   35.000  5.315110          31.00        38.2500   \n",
       "\n",
       "    min2   max2     mean2  ...      std5  1st_quartile5  3rd_quartile5  min6  \\\n",
       "1    0.0   1.70  0.426250  ...  1.999604        35.3625         36.500   0.0   \n",
       "2    0.0   3.00  0.696042  ...  3.849448        30.4575         36.330   0.0   \n",
       "3    0.0   2.83  0.535979  ...  2.411026        28.4575         31.250   0.0   \n",
       "4    0.0   1.58  0.378083  ...  2.488862        22.2500         24.000   0.0   \n",
       "5    0.0   1.50  0.413125  ...  3.318301        20.5000         23.750   0.0   \n",
       "..   ...    ...       ...  ...       ...            ...            ...   ...   \n",
       "84   0.0   2.12  0.506583  ...  2.983976        12.7500         16.500   0.0   \n",
       "85   0.0   3.34  0.486167  ...  4.296574        13.0000         18.565   0.0   \n",
       "86   0.0  14.50  3.995729  ...  3.092094        14.7500         18.670   0.0   \n",
       "87   0.0  13.05  4.450771  ...  3.133564        14.6275         18.750   0.0   \n",
       "88   0.0  13.44  4.200896  ...  3.155015        14.2500         18.500   0.0   \n",
       "\n",
       "    max6     mean6  median6      std6  1st_quartile6  3rd_quartile6  \n",
       "1   1.79  0.493292    0.430  0.513506          0.000          0.940  \n",
       "2   2.18  0.613521    0.500  0.524317          0.000          1.000  \n",
       "3   1.79  0.383292    0.430  0.389164          0.000          0.500  \n",
       "4   5.26  0.679646    0.500  0.622534          0.430          0.870  \n",
       "5   2.96  0.555313    0.490  0.487826          0.000          0.830  \n",
       "..   ...       ...      ...       ...            ...            ...  \n",
       "84  5.72  0.911979    0.830  0.666161          0.470          1.220  \n",
       "85  5.73  0.842271    0.710  0.722165          0.430          1.090  \n",
       "86  9.74  3.394125    3.100  1.792090          2.105          4.425  \n",
       "87  8.96  3.378479    3.085  1.787360          2.060          4.440  \n",
       "88  8.99  3.244396    3.000  1.630983          2.120          4.240  \n",
       "\n",
       "[88 rows x 42 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features = ['min', 'max', 'mean', 'median', 'std', '1st_quart', '3rd_quart']\n",
    "stat = collections.defaultdict(dict)\n",
    "ind = 0\n",
    "for datafile in trainset+testset: # one datafile is one instance, is one dataset file.\n",
    "    ind += 1\n",
    "    for i, time_series_col in enumerate(col_name[1:]): # ['avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\n",
    "        series_data = datafile[time_series_col].describe()\n",
    "        series_num = i+1\n",
    "        stat[ind]['min' + str(series_num)] = series_data['min']\n",
    "        stat[ind]['max' + str(series_num)] = series_data['max']\n",
    "        stat[ind]['mean' + str(series_num)] = series_data['mean']\n",
    "        stat[ind]['median' + str(series_num)] = series_data['50%']\n",
    "        stat[ind]['std' + str(series_num)] = series_data['std']\n",
    "        stat[ind]['1st_quartile' + str(series_num)] = series_data['25%']\n",
    "        stat[ind]['3rd_quartile' + str(series_num)] = series_data['75%']\n",
    "stat_table = pd.DataFrame(stat).T\n",
    "stat_table # first 69 lines are for trainset, last 19 lines are for testset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d73347",
   "metadata": {},
   "source": [
    "iii. Estimate the standard deviation of each of the time-domain features you extracted from the data. Then, use Python’s bootstrapped or any other method to build a 90% bootsrap confidence interval for the standard deviation of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c95e0dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_deviation</th>\n",
       "      <th>90%_bootstrap_confidence_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min1</th>\n",
       "      <td>9.515445</td>\n",
       "      <td>[8.208716366166229, 10.72700749323007]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max1</th>\n",
       "      <td>4.369322</td>\n",
       "      <td>[3.2458553594488477, 5.307806963314891]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean1</th>\n",
       "      <td>5.305314</td>\n",
       "      <td>[4.709658173537759, 5.861402707264918]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median1</th>\n",
       "      <td>5.409056</td>\n",
       "      <td>[4.743047416911437, 5.942663695258046]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std1</th>\n",
       "      <td>1.762056</td>\n",
       "      <td>[1.5542719415749657, 1.9266113285432824]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quartile1</th>\n",
       "      <td>6.118526</td>\n",
       "      <td>[5.50681057823348, 6.637550324901437]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quartile1</th>\n",
       "      <td>5.109643</td>\n",
       "      <td>[4.217848403812224, 5.775157647339774]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max2</th>\n",
       "      <td>5.033882</td>\n",
       "      <td>[4.599466179892982, 5.381775678387139]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean2</th>\n",
       "      <td>1.565194</td>\n",
       "      <td>[1.3981886989863266, 1.6944130542032474]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median2</th>\n",
       "      <td>1.404197</td>\n",
       "      <td>[1.2121855248977749, 1.5253816660572512]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std2</th>\n",
       "      <td>0.879068</td>\n",
       "      <td>[0.7968627190017105, 0.9378265101531833]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quartile2</th>\n",
       "      <td>0.940994</td>\n",
       "      <td>[0.8188752895865176, 1.0267403427218957]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quartile2</th>\n",
       "      <td>2.113157</td>\n",
       "      <td>[1.8702482272920486, 2.2964097838026705]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min3</th>\n",
       "      <td>2.939616</td>\n",
       "      <td>[2.748837770933216, 3.0859402721245]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max3</th>\n",
       "      <td>4.847358</td>\n",
       "      <td>[4.106643522723548, 5.460205092897909]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean3</th>\n",
       "      <td>3.98554</td>\n",
       "      <td>[3.443446456807107, 4.494200296116165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median3</th>\n",
       "      <td>4.013397</td>\n",
       "      <td>[3.406978095282612, 4.527805468709336]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std3</th>\n",
       "      <td>0.941316</td>\n",
       "      <td>[0.7592331775484946, 1.1040310031880434]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quartile3</th>\n",
       "      <td>4.196608</td>\n",
       "      <td>[3.5778689317725045, 4.6905458065171795]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quartile3</th>\n",
       "      <td>4.147858</td>\n",
       "      <td>[3.5376071871400456, 4.649893495844285]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max4</th>\n",
       "      <td>2.171183</td>\n",
       "      <td>[1.958526993164645, 2.349807510909446]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean4</th>\n",
       "      <td>1.15947</td>\n",
       "      <td>[1.0698533735974711, 1.2179850602522353]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median4</th>\n",
       "      <td>1.139058</td>\n",
       "      <td>[1.0578414339982487, 1.1961335513327795]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std4</th>\n",
       "      <td>0.455631</td>\n",
       "      <td>[0.4182639578687031, 0.48250231122106185]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quartile4</th>\n",
       "      <td>0.838813</td>\n",
       "      <td>[0.770855662881105, 0.889166906243029]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quartile4</th>\n",
       "      <td>1.543658</td>\n",
       "      <td>[1.419436234707123, 1.6154407802461157]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min5</th>\n",
       "      <td>6.089107</td>\n",
       "      <td>[4.279961549800254, 7.538703866828538]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max5</th>\n",
       "      <td>5.708524</td>\n",
       "      <td>[4.710686215167446, 6.529025664174588]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean5</th>\n",
       "      <td>5.643253</td>\n",
       "      <td>[4.358877877539067, 6.698787696817404]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median5</th>\n",
       "      <td>5.780655</td>\n",
       "      <td>[4.517711681857593, 6.834739958446611]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std5</th>\n",
       "      <td>1.019058</td>\n",
       "      <td>[0.8053942614996169, 1.2074104825800662]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quartile5</th>\n",
       "      <td>6.061727</td>\n",
       "      <td>[4.761921806941212, 7.091166174351091]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quartile5</th>\n",
       "      <td>5.5002</td>\n",
       "      <td>[4.268407741530003, 6.471963011091932]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min6</th>\n",
       "      <td>0.045577</td>\n",
       "      <td>[0.0, 0.07802896990623483]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max6</th>\n",
       "      <td>2.504568</td>\n",
       "      <td>[2.246335526018886, 2.7459906911774223]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean6</th>\n",
       "      <td>1.148232</td>\n",
       "      <td>[1.0498235151678628, 1.207457118418856]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median6</th>\n",
       "      <td>1.080284</td>\n",
       "      <td>[0.9803876626152863, 1.1389861542536903]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std6</th>\n",
       "      <td>0.514668</td>\n",
       "      <td>[0.4746475873982805, 0.5422164958440671]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_quartile6</th>\n",
       "      <td>0.754261</td>\n",
       "      <td>[0.6926390287080405, 0.8049621657733028]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd_quartile6</th>\n",
       "      <td>1.514918</td>\n",
       "      <td>[1.4054783738714005, 1.5932723597079856]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              standard_deviation          90%_bootstrap_confidence_interval\n",
       "min1                    9.515445     [8.208716366166229, 10.72700749323007]\n",
       "max1                    4.369322    [3.2458553594488477, 5.307806963314891]\n",
       "mean1                   5.305314     [4.709658173537759, 5.861402707264918]\n",
       "median1                 5.409056     [4.743047416911437, 5.942663695258046]\n",
       "std1                    1.762056   [1.5542719415749657, 1.9266113285432824]\n",
       "1st_quartile1           6.118526      [5.50681057823348, 6.637550324901437]\n",
       "3rd_quartile1           5.109643     [4.217848403812224, 5.775157647339774]\n",
       "min2                         0.0                                 [0.0, 0.0]\n",
       "max2                    5.033882     [4.599466179892982, 5.381775678387139]\n",
       "mean2                   1.565194   [1.3981886989863266, 1.6944130542032474]\n",
       "median2                 1.404197   [1.2121855248977749, 1.5253816660572512]\n",
       "std2                    0.879068   [0.7968627190017105, 0.9378265101531833]\n",
       "1st_quartile2           0.940994   [0.8188752895865176, 1.0267403427218957]\n",
       "3rd_quartile2           2.113157   [1.8702482272920486, 2.2964097838026705]\n",
       "min3                    2.939616       [2.748837770933216, 3.0859402721245]\n",
       "max3                    4.847358     [4.106643522723548, 5.460205092897909]\n",
       "mean3                    3.98554     [3.443446456807107, 4.494200296116165]\n",
       "median3                 4.013397     [3.406978095282612, 4.527805468709336]\n",
       "std3                    0.941316   [0.7592331775484946, 1.1040310031880434]\n",
       "1st_quartile3           4.196608   [3.5778689317725045, 4.6905458065171795]\n",
       "3rd_quartile3           4.147858    [3.5376071871400456, 4.649893495844285]\n",
       "min4                         0.0                                 [0.0, 0.0]\n",
       "max4                    2.171183     [1.958526993164645, 2.349807510909446]\n",
       "mean4                    1.15947   [1.0698533735974711, 1.2179850602522353]\n",
       "median4                 1.139058   [1.0578414339982487, 1.1961335513327795]\n",
       "std4                    0.455631  [0.4182639578687031, 0.48250231122106185]\n",
       "1st_quartile4           0.838813     [0.770855662881105, 0.889166906243029]\n",
       "3rd_quartile4           1.543658    [1.419436234707123, 1.6154407802461157]\n",
       "min5                    6.089107     [4.279961549800254, 7.538703866828538]\n",
       "max5                    5.708524     [4.710686215167446, 6.529025664174588]\n",
       "mean5                   5.643253     [4.358877877539067, 6.698787696817404]\n",
       "median5                 5.780655     [4.517711681857593, 6.834739958446611]\n",
       "std5                    1.019058   [0.8053942614996169, 1.2074104825800662]\n",
       "1st_quartile5           6.061727     [4.761921806941212, 7.091166174351091]\n",
       "3rd_quartile5             5.5002     [4.268407741530003, 6.471963011091932]\n",
       "min6                    0.045577                 [0.0, 0.07802896990623483]\n",
       "max6                    2.504568    [2.246335526018886, 2.7459906911774223]\n",
       "mean6                   1.148232    [1.0498235151678628, 1.207457118418856]\n",
       "median6                 1.080284   [0.9803876626152863, 1.1389861542536903]\n",
       "std6                    0.514668   [0.4746475873982805, 0.5422164958440671]\n",
       "1st_quartile6           0.754261   [0.6926390287080405, 0.8049621657733028]\n",
       "3rd_quartile6           1.514918   [1.4054783738714005, 1.5932723597079856]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# st_dev=np.std(stat_table) \n",
    "# print(st_dev)\n",
    "\n",
    "std_stat = collections.defaultdict(dict)\n",
    "for feature in stat_table.columns:\n",
    "    std_stat[feature][\"standard_deviation\"] = np.std(stat_table[feature])\n",
    "#     print('The standard deviation of ' + feature + ' is ' + str(np.std(stat_table[feature])))\n",
    "    feature_array = np.array(stat_table[feature])\n",
    "    n = len(feature_array)\n",
    "    bootstrap = []\n",
    "    for i in range(1000):\n",
    "        ind = np.random.randint(0, n, size=n)\n",
    "        data_sample = feature_array[ind]\n",
    "        bootstrap.append(np.std(data_sample))\n",
    "    bootstrap.sort()\n",
    "    a = 1 - 0.9\n",
    "    std_stat[feature][\"90%_bootstrap_confidence_interval\"] = '[' + str(bootstrap[int(1000 * a / 2)]) + ', ' + str(bootstrap[int(1000 * (1 - a / 2))]) + ']'\n",
    "#     print('90% bootstrap confidence interval is: [' + str(bootstrap[int(1000 * a / 2)]) + ', ' + str(bootstrap[int(1000 * (1 - a / 2))]) + ']')\n",
    "std_stat_table = pd.DataFrame(std_stat).T\n",
    "std_stat_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68063cc5",
   "metadata": {},
   "source": [
    "iv. Use your judgement to select the three most important time-domain features (one option may be min, mean, and max)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a493c",
   "metadata": {},
   "source": [
    "1. Mean: to capture the average values of the time series\n",
    "2. First Quartile: to see lower bound values of the series\n",
    "3. Max: to utilise the peak values of the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81644e7",
   "metadata": {},
   "source": [
    "<b>2. ISLR 3.7.4</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b23c78",
   "metadata": {},
   "source": [
    "I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. Y = β0 +β1X +β2X2 +β3X3 +ε."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d78db",
   "metadata": {},
   "source": [
    "(a) Suppose that the true relationship between X and Y is linear, i.e. Y = β0 + β1X + ε. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2225e5b",
   "metadata": {},
   "source": [
    "Cubic regression is better. Because cubic regression is more flexible than linear model, when it only has 100 obseavations, cubic regression will get a good fitting than linear regression. When we use polynomial features, we get more parameters, and the generated curve will try to fit more data points than a linear line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba6c12f",
   "metadata": {},
   "source": [
    "(b) Answer (a) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f55edac",
   "metadata": {},
   "source": [
    "I would expect the linear regression to perform slightly better than the cubic regression. We may have overfitting training on 100 observations, so cubic regression may be less accurate when it predicts the unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca31d2a",
   "metadata": {},
   "source": [
    "(c) Suppose that the true relationship between X and Y is not linear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebdf5f",
   "metadata": {},
   "source": [
    "Cubic regression will has a lower training RSS. Since we don't know how far it is from line, so here more parameters mean the regression model will be more flwxible, is able to fit more data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ede6ce",
   "metadata": {},
   "source": [
    "(d) Answer (c) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4529f",
   "metadata": {},
   "source": [
    "I think it would depends on the real relationship between X and Y. If it is a strong non-linear relationship, then we would obviously expect the cubic regression to have a lower test RSS. But if it is close to linear, or maybe a mildly non-linear relationship, linear model may perform better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
